{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e380e14",
   "metadata": {},
   "source": [
    "# Repaso $ 4to $ Parcial \n",
    "### Laboratorio de Aprendizaje Estadístico\n",
    "José Armando Melchor Soto\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf97611",
   "metadata": {},
   "source": [
    "## Temario\n",
    "\n",
    "1. PCA \n",
    "    - Regresión \n",
    "    - Clasificación\n",
    "    - Interpretación Componentes principales\n",
    "\n",
    "2. KMeans\n",
    "    - Clusters\n",
    "    - Método del codo\n",
    "\n",
    "3. Shaps\n",
    "    - Interpretación de modelo\n",
    "    - Importancia de Variables\n",
    "    \n",
    "4. Efecto Causal \n",
    "    - S learner\n",
    "    - X learner\n",
    "    - T leraner\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abaf759",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ca3544",
   "metadata": {},
   "source": [
    "- ¿Qué es?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff06551",
   "metadata": {},
   "source": [
    "El Análisis de Componentes Principales (PCA, por sus siglas en inglés Principal Component Analysis) es una técnica estadística clásica cuyo objetivo es reducir la dimensionalidad de un conjunto de datos, preservando la mayor cantidad posible de la varianza original. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10af0fa6",
   "metadata": {},
   "source": [
    "- ¿Cómo se calcula?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f95cac0",
   "metadata": {},
   "source": [
    "\n",
    "Su objetivo principal es reducir la dimensionalidad , pero necesita la proyección de un vector $x_i$ sobre el componente principal $u_1$ , que se termina expresando como:\n",
    "$$\n",
    "\\text{Proy}_{u_1}(x_i) = u_1^T x_i\n",
    "$$\n",
    "\n",
    "Donde su principal objetivo es explicar la varianza como:\n",
    "\n",
    "\n",
    "$$ \\text{Varianza} = \\frac{1}{N} \\sum_{n=1}^N \\left( u_1^T x_n - u_1^T \\bar{x} \\right)^2 $$\n",
    "\n",
    "\n",
    "Que se termina agrupando los terminos , quedando como:\n",
    "$$u_1^T S u_1$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $S$ es la matriz de covarianza de los datos.\n",
    "- $u_1$ indica la dirección del primer componente principal, es decir, la dirección donde los datos se extienden más.\n",
    "\n",
    "Se busca encontrar el vector $u_1$ que maximice la varianza de las proyecciones.\n",
    "\n",
    "$$\n",
    "\\max_{u_1} u_1^T S u_1\n",
    "$$\n",
    "\n",
    "sujeto a la restricción:\n",
    "\n",
    "$$\n",
    "\\|u_1\\| = 1\n",
    "$$\n",
    "\n",
    "Con esto tratamos de máximizar la función para el vector $x_1$\n",
    "\n",
    "$$\n",
    "\\max_{u_1} u_1^T S u_1\n",
    "$$\n",
    "\n",
    "Lo que nos lleva a plantearnos hacer esta resolución con los multiplicadores de Lagrange\n",
    "Quedando la función Lagrangiana como :\n",
    "$$\n",
    "\\mathcal{L}(u_1, \\lambda) = u_1^T S u_1 - \\lambda (u_1^T u_1 - 1)\n",
    "$$\n",
    "donde \n",
    "- $\\lambda$ es el multiplicador de Lagrange.\n",
    "\n",
    "Lo que nos lleva a derivar respecto a $u_1$ e igualar a cero:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial u_1} = 2 S u_1 - 2 \\lambda u_1 = 0\n",
    "$$\n",
    "\n",
    "lo que se puede reorganizar como:\n",
    "\n",
    "$$\n",
    "S u_1 = \\lambda u_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f21e68",
   "metadata": {},
   "source": [
    "- ¿Cómo se interpreta?\n",
    "\n",
    "    Esto es precisamente la **definición de un problema de autovalores (eigenvalores)**:\n",
    "\n",
    "    - $u_1$ es un **vector propio** (*eigenvector*) de la matriz de covarianza $S$.\n",
    "    - $\\lambda$ es el **valor propio** (*eigenvalue*) asociado.\n",
    "\n",
    "    - El **primer componente principal** $u_1$ es el **eigenvector correspondiente al eigenvalor más grande** de $S$.\n",
    "\n",
    "    - La segunda componente principal será aquella que resuelva con el segundo eigenvalor más grande y así sucesivamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369fa646",
   "metadata": {},
   "source": [
    "- ¿Cómo se interpreta la gráfica?\n",
    "\n",
    "    - El diagrama muestra los datos originales dispersos en dos dimensiones.\n",
    "    - $u_1$ indica la **dirección del primer componente principal**, es decir, la dirección donde los datos **se extienden más**.\n",
    "    - La idea es **proyectar** los datos sobre $u_1$ para **capturar la máxima varianza** en una sola dimensión.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4376a84f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58bbbd0",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06527821",
   "metadata": {},
   "source": [
    "- ¿Qué son?\n",
    "\n",
    "Es un algoritmo de `Aprendizaje no supervisado` que se utiliza para resolver problemas de clustering. Su objetivo es dividir un conjunto de datos en clusters de manera que los elementos dentro de cada grupo sean lo más parecidos posible entre sí y diferentes de los elementos en otros grupos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7401e5b6",
   "metadata": {},
   "source": [
    "- ¿Cómo se calculan?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde773b2",
   "metadata": {},
   "source": [
    "--- Teoria Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a126e8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ae6aaf",
   "metadata": {},
   "source": [
    "## Shaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fade33",
   "metadata": {},
   "source": [
    "- ¿Qué son?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d29da2",
   "metadata": {},
   "source": [
    "Se hacen todas las permutaciones posibles de las variables de tu dataset y se calcula la contribución marginal de cada una de las variables en cada una de estas permutaciones. Por último, se promedian estas contribuciones marginales de cada variables para obtener su shap value.\n",
    "\n",
    "La contribución marginal de la variable representa como cambia la predicción de un modelo al agregar una nueva variable.\n",
    "\n",
    "Partes de un modelo base sin variables (promedio) y vas agregando una variable a la vez donde en cada paso obtienes su contribución marginal. Por lo tanto la predicción de un modelo es explicada por: $f(x_1,x_2,x_3) = \\text{modelo base} + SHAPx_1 + SHAPx_2 + SHAPx_3$. Esto porque los shap values representan las contribuciones de las variables al modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d9e332",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0922d43",
   "metadata": {},
   "source": [
    "## Efecto Causal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9376811c",
   "metadata": {},
   "source": [
    "#### S learner  (Discreto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8cb338",
   "metadata": {},
   "source": [
    "- ¿Qué es?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c93689b",
   "metadata": {},
   "source": [
    "Entrenas tu modelo con los datos originales, posteriormente modificas tus datos para que todos tengan el tratamiento (1) y también para que nadie tenga tratamiento (0), estos datos los utilizas para hacer predicciones donde a las predicciones con tratamiento le restas las predicciones sin tratamiento, y la diferencia obtenida representa el CATE de tener el trtamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85761e3b",
   "metadata": {},
   "source": [
    "##### S learner (Tratamiento Continuo )\n",
    "\n",
    "- ¿Qué es?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a7789f",
   "metadata": {},
   "source": [
    "Entrenas tu modelo sobre los datos originales. Posteriormente sobre una obervación de tus datos defines sobre que variable continua vas a analizar su efecto. A esta variable le das multiples valores distintos y de forma iterativa usas tu modelo para hacer predicciones con los distintos valores y ver que efecto tiene sobre la predicción. Por ejemplo como distintos precios de un producto podrían afectar las posibles ventas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8030864",
   "metadata": {},
   "source": [
    "#### X learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a08f40d",
   "metadata": {},
   "source": [
    "- ¿Qué es?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f9205",
   "metadata": {},
   "source": [
    "\n",
    "Haces dos modelos al igual que en el T learner los cuales son model_t0 y model_t1. Con estos modelos se van a calcular D0 y D1. Para D0 calculas lo que paso menos lo que pasaría sin tratamiento donde a y_train le restas la predicción de model_t0 usando su contrafactual. Pra D1 obtienes lo que habría pasado menos lo que paso donde usas las predicciones del model_t1 con los datos de su contrafactual menos lo que paso. Tanto D0 como D1 son el efecto causal del contrafactual de cada grupo, es decir, usas lo que hubiera pasado.\n",
    "\n",
    "Ya que tienes calculados D0 y D1 se entranan dos nuevos modelos los cuales serán utilizados para predecir el efecto causal (CATE) condicional dentro de cada grupo, es decr, calcula el CATE para los grupos con tratmiento y sin tratamiento, para ello entrenas md0 con con los datos con tratamiento como `X` y D0 como `y` y de forma inversa entrenas md1 con los datos sin tratamiento como `X`y D1 como `y`. \n",
    "\n",
    "Después se neecsita calcular el propensity score, el cual dice la probabilidad de tener el tratamiento condicional a X. Para esto se hace un modelo de clasificación donde tus datos originales son la varible `X` y si tienen tratamiento o no la variable `y` y realizas las predicciones de probabilidades. Por último usas md0 y md1 para obtener tus CATE's y con las probabilidades del propensity score ponderas el CATE para darle el peso adecuado dada la probabilidad de tener o no el tratamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71684d0",
   "metadata": {},
   "source": [
    "#### T learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e66128",
   "metadata": {},
   "source": [
    "- ¿Qué es?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f1d24",
   "metadata": {},
   "source": [
    "Tus datos los modificas para tener dos datasets diferentes, uno donde todos tienen el tratamiento (1) y otro donde nadie tiene el tratamiento (0). Con estos datos entrenas dos modelos diferentes, uno con los datos con el tratamiento (model_t1) y otro con los datos sin tratamiento (model_t0). Posteriormente usas ambos modelos para hacer las predicciones con tus datos de test originales, donde un modelo tiene un sesgo hacia el tratamiento y el otro hacia los que no lo tienen por los datos con los que se entrenaron.\n",
    "\n",
    "Por último las predicciones realizadas por el model_t1 le restas las predicciones de model_t0 y la diferencia entre esta spredicciones es el CATE provocado por el tratamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c842e945",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e25cb4",
   "metadata": {},
   "source": [
    "## EXTRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e10df3",
   "metadata": {},
   "source": [
    "##### CATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a374dff1",
   "metadata": {},
   "source": [
    "Efecto esperado del tratamiento para los individuos con dicha característica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced90f9",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
