{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repaso $2do $ Parcial \n",
    "### Laboratorio de Aprendizaje Estadístico\n",
    "José Armando Melchor Soto\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temario\n",
    "\n",
    "- Regresion logistica \n",
    "    - ¿Qué es? ¿Cómo se calcula? Por qué, descenso en gradiente etc \n",
    "\n",
    "- Odds y log odds\n",
    "\n",
    "- Softmax\n",
    "\n",
    "- Analisis del discriminante lineal \n",
    "\n",
    "- Redes neuronales \n",
    "\n",
    "- AUC   \n",
    "    - ¿Qué es? ¿Por qué se utiliza?\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Qué es?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un modelo de clasificación que se utiliza para clasificar entre dos clases o más usando la función sigmoide, que transforma cualquier número real en un valor entre 0 y 1, lo que permite interpretarlo como una probabilidad.\n",
    "Si la probabilidad es mayor a un cierto umbral (0.5), la observación se asigna a una clase; si es menor, se asigna a la otra. Para problemas con más de dos clases, se usa una generalización con la función softmax.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Cómo se calcula?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza la función sigmoide para modelar la probabilidad de éxito en la regresión logística.\n",
    "\n",
    "$$\n",
    "p(y = 1 | X) = \\sigma(\\theta^T X) = \\frac{1}{1 + e^{-\\theta^T X}}\n",
    "$$\n",
    "\n",
    "Donde $\\sigma(z)$ es la función sigmoide:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "Función de Verosimilitud\n",
    "Como \\( y \\) sigue una distribución de Bernoulli, la función de verosimilitud es:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\prod_{i=1}^{m} p(y_i | X_i; \\theta) = \\prod_{i=1}^{m} \\left[ \\sigma(\\theta^T X_i) \\right]^{y_i} \\cdot \\left[ 1 - \\sigma(\\theta^T X_i) \\right]^{(1 - y_i)}\n",
    "$$\n",
    "\n",
    "Tomamos el logaritmo de la verosimilitud:\n",
    "\n",
    "$$\n",
    "\\log L(\\theta) = \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "$$\n",
    "\n",
    "Función de Pérdida\n",
    "Para estimar $\\theta$, maximizamos la log-verosimilitud. \n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Por qué descenso en gradiente? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El descenso en gradiente encuentra los valores óptimos de $\\theta$ iterativamente, ajustándolos en la dirección del gradiente para minimizar la función de pérdida. Al contrario, lo que buscamos es el ascenso en gradiente, ya que en la función de pérdida de la regresión logística, a diferencia de la regresión lineal, esta es creciente y busca maximizarse. Por lo tanto, en la regresión logistica necesitamos *maximizar* y no minimizar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oods y Log-Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Qué son los Odds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es la probabilidad de exito contra la fracaso. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$odds = \\frac{p}{1-p}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Los odds podrían llegar a ser muy volatiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Qué son los Log-Odds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A los Odds , se le aplica logaritmo natural ya que este crecimiento es exponencial. \n",
    "\n",
    "$$log(odds) = log(\\frac{p}{1-p})$$\n",
    "\n",
    "\n",
    "Una vez se obtienen los coeficientes , se utiliza logit z como: $$z = \\Theta ^T X $$\n",
    "\n",
    "y luego se aplica la función sigmoide para transformar z en una probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Qué es?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es una función que convierte los logits en probabilidades, asegurando que todas sean positivas y sumen uno. Permite clasificar entre múltiples clases al modelar una distribución de probabilidades sobre ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Su ecuación es:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y = k | \\mathbf{x}) = \\frac{\\exp(\\mathbf{w}_k \\cdot \\mathbf{x} + b_k)}{\\sum_{j=1}^{K} \\exp(\\mathbf{w}_j \\cdot \\mathbf{x} + b_j)}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde, para cada $k$, se calcula un logit utilizando el vector de peso $w_k$ y el bias $b_k$. La función exponencial garantiza que los valores sean siempre positivos, y la normalización mediante la suma asegura que todas las probabilidades sumen uno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de Discriminante Lineal  (GDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Qué es?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un modelo de clasificación supervisada utilizado en aprendizaje automático y estadística, que asume que los datos de cada clase siguen una distribución normal. Donde se estiman las probabilidades de pertenencia a cada clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "     P(\\mathbf{x} | y = k) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma_k|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x} - \\mu_k)^T \\Sigma_k^{-1} (\\mathbf{x} - \\mu_k)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde:\n",
    "- $\\mathbf{x}$ es el vector de características.\n",
    "- $\\mu_k$ es el vector de medias de la clase \\( k \\).\n",
    "- $\\Sigma_k$ es la matriz de covarianza de la clase \\( k \\).\n",
    "- $\\Sigma_k|$ es el determinante de la matriz de covarianza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Cuáles son las clases?\n",
    "\n",
    "El GDA se utiliza para problemas de clasificación en los que las etiquetas $y$ son discretas (por ejemplo, clasificación binaria o multiclase).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Cuál es la Probabilidad a priori?\n",
    "\n",
    "El modelo también estima la probabilidad a priori $P(y = k)$ de cada clase, que representa la proporción de datos que pertenecen a la clase $k$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Cuál es la Regla de Bayes?\n",
    "\n",
    "Para calcular la probabilidad posterior se utiliza la regla de Bayes , donde P(x) es la normalización constante.\n",
    "     $$\n",
    "P(y = k | \\mathbf{x}) = \\frac{P(\\mathbf{x} | y = k) P(y = k)}{P(\\mathbf{x})}\n",
    "     $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desición de clasificación\n",
    "\n",
    "El punto $x$ se asigna a la clase $k$ que maximiza la probabilidad posterior $P(y=k|x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tipos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **GDA con matriz de covarianza compartida**:  \n",
    "    Todas las clases comparten la misma matriz de covarianza $\\Sigma$, esto ayuda a simplificar el modelo y reduce el número de parámetros a estimar.\n",
    "\n",
    "- **GDA con matriz de covarianza específica**:  \n",
    "    Cada clase tiene su propia matriz de covarianza $\\Sigma_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pasos para implementar GDA\n",
    "\n",
    "- Estimación de parámetros\n",
    "- Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El GDA es un modelo probabilístico de clasificación que asume que los datos siguen una distribución gaussiana. Es eficiente, pero su suposición de normalidad puede no ser válida y puede ser inestable en alta dimensionalidad. Está relacionado con el LDA y la Regresión Logística, con diferencias en las suposiciones sobre la distribución de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué son?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son modelos inspirados en el funcionamiento del cerebro humano y están formadas por neuronas artificiales organizadas en capas (entrada, ocultas y salida) que procesan información mediante conexiones ponderadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Forward Propagation**  \n",
    "El proceso inicia con la entrada de datos, que atraviesa varias capas de la red. En cada capa, los datos se transforman mediante una combinación lineal con pesos específicos y luego pasan por una función de activación, que puede variar entre capas. Al final, el modelo genera un único resultado, producto de la combinación de las salidas de todas las capas anteriores.  \n",
    "\n",
    "### **Backpropagation**  \n",
    "Dado que la predicción inicial suele ser imprecisa, el error se propaga hacia atrás a través de la red, distribuyéndolo entre las neuronas. Para corregir estos errores, se ajustan los pesos en cada capa, optimizando la combinación lineal utilizada en el **forward propagation**, con el objetivo de mejorar la precisión del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué es?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **AUC** es una métrica que mide el rendimiento de un modelo y corresponde al área bajo la curva **ROC**. Intuitivamente, representa la probabilidad de que, al comparar dos instancias al azar (una de clase 1 y otra de clase 0), el modelo asigne una mayor probabilidad a la instancia de clase 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué se utiliza?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalúa qué tan bien el modelo distingue entre clases, siendo útil especialmente en conjuntos de datos desbalanceados, donde métricas como la precisión pueden ser engañosas."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
